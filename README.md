# Resume Categorization Project

## ğŸ“Œ Overview
This project tackles the challenge of **resume categorization** using machine learning and deep learning techniques. Companies often face the daunting task of sifting through numerous resumes for each job opening. This app aims to automate and streamline this process by predicting the job category a given resume belongs to. By using a trained model, the app can quickly suggest the appropriate job category for each resume, saving time and resources for recruiters.

## ğŸ› ï¸ Technologies Used
- **Python**
- **Scikit-learn** (Machine Learning Models: KNN, SVC, Random Forest)
- **TensorFlow/Keras** (Deep Learning Models: MLP, RNN, LSTM, BI-LSTM)
- **Streamlit** (Web Application)
- **NLTK/Regex** (Text Preprocessing)
- **Pandas/Numpy** (Data Handling)
- **PyPDF2/python-docx** (File Parsing)

## ğŸ“‚ Project Structure
```
Resume-Categorization/
â”œâ”€â”€ app/                      # Streamlit application files
â”‚   â”œâ”€â”€ main.py               # Main Streamlit app script
â”‚   â”œâ”€â”€ knn.pkl               # Serialized KNN model
â”‚   â”œâ”€â”€ svc.pkl               # Serialized SVC model
â”‚   â”œâ”€â”€ rf.pkl                # Serialized Random Forest model
â”‚   â”œâ”€â”€ mlp.pkl               # Serialized MLP model
â”‚   â”œâ”€â”€ ensemble.pkl          # Serialized Ensemble model
â”‚   â”œâ”€â”€ tfidf.pkl             # Serialized TF-IDF vectorizer
â”‚   â””â”€â”€ encoder.pkl           # Serialized Label Encoder
â”œâ”€â”€ notebooks/                # Jupyter notebooks for development
â”‚   â””â”€â”€ Resume_Categorization.ipynb  # Main project notebook
â”œâ”€â”€ data/                     # Dataset files
â”‚   â””â”€â”€ UpdatedResumeDataSet.csv     # Resume dataset
â”œâ”€â”€ requirements.txt          # Python dependencies
â””â”€â”€ README.md                 # This file
```

## ğŸš€ Installation
1. Clone the repository:
   ```bash
   git clone https://github.com/your-username/Resume-Categorization.git
   cd Resume-Categorization
   ```

2. Create a virtual environment (recommended):
   ```bash
   python -m venv venv
   source venv/bin/activate  # On Windows use `venv\Scripts\activate`
   ```

3. Install dependencies:
   ```bash
   pip install -r requirements.txt
   ```

## ğŸƒâ€â™‚ï¸ Running the Application
To run the Streamlit application:
```bash
streamlit run app/main.py
```

## ğŸ“Š Models Implemented
### Machine Learning Models
- **K-Nearest Neighbors (KNN)**
- **Support Vector Machine (SVC)**
- **Random Forest**

### Deep Learning Models
- **Multilayer Perceptron (MLP)**
- **Recurrent Neural Network (RNN)**
- **Long Short-Term Memory (LSTM)**
- **Bidirectional LSTM (BI-LSTM)**

### Ensemble Model
- **Voting Classifier** (Combines KNN, SVC, and Random Forest)

## ğŸ“ Dataset
The project uses the [Resume Dataset](https://www.kaggle.com/datasets/gauravduttakiit/resume-dataset) from Kaggle. This dataset consists of resumes categorized into 25 distinct job fields.

## ğŸ§  Key Features
1. **Text Preprocessing Pipeline**
   - URL removal
   - Special character removal
   - Whitespace normalization
   - Stopword removal

2. **Multiple Model Comparison**
   - Compare predictions from different models
   - View accuracy metrics for each approach

3. **File Upload Support**
   - Accepts PDF, DOCX, and TXT files
   - Automatic text extraction

4. **Interactive Web Interface**
   - Easy-to-use file upload
   - Clear results display
   - Model performance comparison

## ğŸ‘¥ Team Members
- [Abdelrahman Mahmoud](https://abdelrahmanmah.github.io/SafeZoneInc/Abdelrahman.html)
- [GannaTullah Gouda](https://gannaasaad.github.io/index.html)
- [Ahmed Khaled](https://Ahmedkhaled51.github.io/)
- [Ali Mohamed](https://aliiimohamedaliii.github.io/My-portfolio/)

## ğŸ“œ License
This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ¤ Contributing
Contributions are welcome! Please open an issue or submit a pull request for any improvements.

---

ğŸŒŸ **Happy resume categorizing!** ğŸŒŸ
